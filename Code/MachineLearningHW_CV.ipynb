{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.775000e-05</td>\n",
       "      <td>-2.775000e-05</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.494000e-05</td>\n",
       "      <td>-1.494000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.761000e-06</td>\n",
       "      <td>-3.761000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1       CONFIRMED              0              0              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3  FALSE POSITIVE              0              1              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0    9.488036     2.775000e-05    -2.775000e-05   170.538750   \n",
       "1   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "2   19.899140     1.494000e-05    -1.494000e-05   175.850252   \n",
       "3    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "4    2.525592     3.761000e-06    -3.761000e-06   171.595550   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.002160  ...           -81.0      4.467           0.064   \n",
       "1          0.003520  ...           -81.0      4.467           0.064   \n",
       "2          0.000581  ...          -176.0      4.544           0.044   \n",
       "3          0.000115  ...          -174.0      4.564           0.053   \n",
       "4          0.001130  ...          -211.0      4.438           0.070   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "2          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "3          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "4          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.141651      15.347  \n",
       "2  48.134129      15.436  \n",
       "3  48.285210      15.597  \n",
       "4  48.226200      15.509  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cumulative.csv\")\n",
    "df = df.drop(columns=[\"rowid\", \"kepid\", \"kepoi_name\", \"kepler_name\", \"koi_pdisposition\", \"koi_score\", \"koi_tce_delivname\"])\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CONFIRMED' 'FALSE POSITIVE' 'CANDIDATE']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"koi_disposition\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8744, 40) (8744,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"koi_disposition\", axis=1)\n",
    "y = df[\"koi_disposition\"].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288.678554</td>\n",
       "      <td>5.932000e-03</td>\n",
       "      <td>-5.932000e-03</td>\n",
       "      <td>143.840300</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>-0.014600</td>\n",
       "      <td>...</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>4.667</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>298.98932</td>\n",
       "      <td>48.077171</td>\n",
       "      <td>13.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.244916</td>\n",
       "      <td>1.332000e-04</td>\n",
       "      <td>-1.332000e-04</td>\n",
       "      <td>136.036500</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>-0.021200</td>\n",
       "      <td>...</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>295.08090</td>\n",
       "      <td>43.953239</td>\n",
       "      <td>13.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666962</td>\n",
       "      <td>8.040000e-07</td>\n",
       "      <td>-8.040000e-07</td>\n",
       "      <td>133.719065</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>4.484</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>296.05377</td>\n",
       "      <td>38.894260</td>\n",
       "      <td>13.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.156816</td>\n",
       "      <td>1.201000e-05</td>\n",
       "      <td>-1.201000e-05</td>\n",
       "      <td>174.135110</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>4.494</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>289.59476</td>\n",
       "      <td>44.141949</td>\n",
       "      <td>15.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.954458</td>\n",
       "      <td>3.496000e-05</td>\n",
       "      <td>-3.496000e-05</td>\n",
       "      <td>135.484620</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>-0.005430</td>\n",
       "      <td>...</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>4.306</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>295.90891</td>\n",
       "      <td>42.988209</td>\n",
       "      <td>14.406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "9013              1              0              0              0  288.678554   \n",
       "7027              0              0              0              0    5.244916   \n",
       "8203              0              1              0              0    2.666962   \n",
       "257               0              0              0              0    7.156816   \n",
       "6728              0              0              0              0    7.954458   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "9013     5.932000e-03    -5.932000e-03   143.840300          0.014600   \n",
       "7027     1.332000e-04    -1.332000e-04   136.036500          0.021200   \n",
       "8203     8.040000e-07    -8.040000e-07   133.719065          0.000254   \n",
       "257      1.201000e-05    -1.201000e-05   174.135110          0.001330   \n",
       "6728     3.496000e-05    -3.496000e-05   135.484620          0.005430   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "9013         -0.014600  ...          -131.0      4.667           0.054   \n",
       "7027         -0.021200  ...          -158.0      4.486           0.078   \n",
       "8203         -0.000254  ...          -216.0      4.484           0.040   \n",
       "257          -0.001330  ...           -75.0      4.494           0.077   \n",
       "6728         -0.005430  ...          -259.0      4.306           0.132   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "9013          -0.027     0.575          0.045         -0.056  298.98932   \n",
       "7027          -0.182     0.878          0.231         -0.099  295.08090   \n",
       "8203          -0.229     0.974          0.358         -0.084  296.05377   \n",
       "257           -0.027     0.838          0.033         -0.066  289.59476   \n",
       "6728          -0.198     1.196          0.378         -0.204  295.90891   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "9013  48.077171      13.145  \n",
       "7027  43.953239      13.695  \n",
       "8203  38.894260      13.968  \n",
       "257   44.141949      15.460  \n",
       "6728  42.988209      14.406  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8504117108874657\n",
      "Testing Data Score: 0.8366880146386093\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the `C` and `gamma` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 2, 3, 10],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.5]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1, gamma=0.0001, score=0.850480109739369, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.0001, score=0.8449222323879232, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.0001, score=0.8324942791762013, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ....... C=1, gamma=0.0005, score=0.850480109739369, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0005, score=0.8449222323879232, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0005, score=0.8324942791762013, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ........ C=1, gamma=0.001, score=0.850480109739369, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.8449222323879232, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.8324942791762013, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ........ C=1, gamma=0.005, score=0.850480109739369, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ....... C=1, gamma=0.005, score=0.8449222323879232, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ....... C=1, gamma=0.005, score=0.8324942791762013, total=   0.4s\n",
      "[CV] C=1, gamma=0.5 ..................................................\n",
      "[CV] .......... C=1, gamma=0.5, score=0.850480109739369, total=   0.4s\n",
      "[CV] C=1, gamma=0.5 ..................................................\n",
      "[CV] ......... C=1, gamma=0.5, score=0.8449222323879232, total=   0.4s\n",
      "[CV] C=1, gamma=0.5 ..................................................\n",
      "[CV] ......... C=1, gamma=0.5, score=0.8324942791762013, total=   0.4s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ....... C=2, gamma=0.0001, score=0.862368541380887, total=   0.4s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=2, gamma=0.0001, score=0.8563586459286368, total=   0.5s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=2, gamma=0.0001, score=0.8434782608695652, total=   0.4s\n",
      "[CV] C=2, gamma=0.0005 ...............................................\n",
      "[CV] ....... C=2, gamma=0.0005, score=0.862368541380887, total=   0.4s\n",
      "[CV] C=2, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=2, gamma=0.0005, score=0.8563586459286368, total=   0.4s\n",
      "[CV] C=2, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=2, gamma=0.0005, score=0.8434782608695652, total=   0.4s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ........ C=2, gamma=0.001, score=0.862368541380887, total=   0.4s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ....... C=2, gamma=0.001, score=0.8563586459286368, total=   0.5s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ....... C=2, gamma=0.001, score=0.8434782608695652, total=   0.4s\n",
      "[CV] C=2, gamma=0.005 ................................................\n",
      "[CV] ........ C=2, gamma=0.005, score=0.862368541380887, total=   0.4s\n",
      "[CV] C=2, gamma=0.005 ................................................\n",
      "[CV] ....... C=2, gamma=0.005, score=0.8563586459286368, total=   0.4s\n",
      "[CV] C=2, gamma=0.005 ................................................\n",
      "[CV] ....... C=2, gamma=0.005, score=0.8434782608695652, total=   0.4s\n",
      "[CV] C=2, gamma=0.5 ..................................................\n",
      "[CV] .......... C=2, gamma=0.5, score=0.862368541380887, total=   0.4s\n",
      "[CV] C=2, gamma=0.5 ..................................................\n",
      "[CV] ......... C=2, gamma=0.5, score=0.8563586459286368, total=   0.4s\n",
      "[CV] C=2, gamma=0.5 ..................................................\n",
      "[CV] ......... C=2, gamma=0.5, score=0.8434782608695652, total=   0.5s\n",
      "[CV] C=3, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0001, score=0.8673982624599909, total=   0.4s\n",
      "[CV] C=3, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0001, score=0.8641354071363221, total=   0.4s\n",
      "[CV] C=3, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0001, score=0.8462242562929062, total=   0.4s\n",
      "[CV] C=3, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0005, score=0.8673982624599909, total=   0.4s\n",
      "[CV] C=3, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0005, score=0.8641354071363221, total=   0.4s\n",
      "[CV] C=3, gamma=0.0005 ...............................................\n",
      "[CV] ...... C=3, gamma=0.0005, score=0.8462242562929062, total=   0.4s\n",
      "[CV] C=3, gamma=0.001 ................................................\n",
      "[CV] ....... C=3, gamma=0.001, score=0.8673982624599909, total=   0.4s\n",
      "[CV] C=3, gamma=0.001 ................................................\n",
      "[CV] ....... C=3, gamma=0.001, score=0.8641354071363221, total=   0.4s\n",
      "[CV] C=3, gamma=0.001 ................................................\n",
      "[CV] ....... C=3, gamma=0.001, score=0.8462242562929062, total=   0.4s\n",
      "[CV] C=3, gamma=0.005 ................................................\n",
      "[CV] ....... C=3, gamma=0.005, score=0.8673982624599909, total=   0.4s\n",
      "[CV] C=3, gamma=0.005 ................................................\n",
      "[CV] ....... C=3, gamma=0.005, score=0.8641354071363221, total=   0.4s\n",
      "[CV] C=3, gamma=0.005 ................................................\n",
      "[CV] ....... C=3, gamma=0.005, score=0.8462242562929062, total=   0.4s\n",
      "[CV] C=3, gamma=0.5 ..................................................\n",
      "[CV] ......... C=3, gamma=0.5, score=0.8673982624599909, total=   0.4s\n",
      "[CV] C=3, gamma=0.5 ..................................................\n",
      "[CV] ......... C=3, gamma=0.5, score=0.8641354071363221, total=   0.4s\n",
      "[CV] C=3, gamma=0.5 ..................................................\n",
      "[CV] ......... C=3, gamma=0.5, score=0.8462242562929062, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.8806584362139918, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.8719121683440073, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.8576659038901602, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0005, score=0.8806584362139918, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0005, score=0.8719121683440073, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0005, score=0.8576659038901602, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8806584362139918, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8719121683440073, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8576659038901602, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ...... C=10, gamma=0.005, score=0.8806584362139918, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ...... C=10, gamma=0.005, score=0.8719121683440073, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ...... C=10, gamma=0.005, score=0.8576659038901602, total=   0.4s\n",
      "[CV] C=10, gamma=0.5 .................................................\n",
      "[CV] ........ C=10, gamma=0.5, score=0.8806584362139918, total=   0.4s\n",
      "[CV] C=10, gamma=0.5 .................................................\n",
      "[CV] ........ C=10, gamma=0.5, score=0.8719121683440073, total=   0.4s\n",
      "[CV] C=10, gamma=0.5 .................................................\n",
      "[CV] ........ C=10, gamma=0.5, score=0.8576659038901602, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 2, 3, 10], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001}\n",
      "0.8700823421774931\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['CANDIDATE' 'FALSE POSITIVE' 'CONFIRMED' 'CONFIRMED' 'CONFIRMED'\n",
      " 'FALSE POSITIVE' 'FALSE POSITIVE' 'CONFIRMED' 'CANDIDATE'\n",
      " 'FALSE POSITIVE']\n",
      "First 10 Actual labels: ['CANDIDATE', 'FALSE POSITIVE', 'CANDIDATE', 'CONFIRMED', 'CONFIRMED', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CANDIDATE', 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test_scaled)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.83      0.59      0.69       528\n",
      "FALSE POSITIVE       0.70      0.87      0.77       568\n",
      "     CANDIDATE       0.98      1.00      0.99      1090\n",
      "\n",
      "     micro avg       0.86      0.86      0.86      2186\n",
      "     macro avg       0.84      0.82      0.82      2186\n",
      "  weighted avg       0.87      0.86      0.86      2186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=['CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Score: 0.8321134492223239\n"
     ]
    }
   ],
   "source": [
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['CONFIRMED' 'FALSE POSITIVE' 'CONFIRMED' 'CONFIRMED' 'CONFIRMED'\n",
      " 'FALSE POSITIVE' 'FALSE POSITIVE' 'CONFIRMED' 'CANDIDATE'\n",
      " 'FALSE POSITIVE']\n",
      "First 10 Actual labels: ['CANDIDATE', 'FALSE POSITIVE', 'CANDIDATE', 'CONFIRMED', 'CONFIRMED', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CANDIDATE', 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the disposition values\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_y_train = to_categorical(encoded_y_train)\n",
    "one_hot_y_test = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=40))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 4,403\n",
      "Trainable params: 4,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/250\n",
      " - 1s - loss: 0.7290 - acc: 0.6674\n",
      "Epoch 2/250\n",
      " - 1s - loss: 0.4127 - acc: 0.8082\n",
      "Epoch 3/250\n",
      " - 0s - loss: 0.3673 - acc: 0.8207\n",
      "Epoch 4/250\n",
      " - 0s - loss: 0.3502 - acc: 0.8317\n",
      "Epoch 5/250\n",
      " - 0s - loss: 0.3413 - acc: 0.8320\n",
      "Epoch 6/250\n",
      " - 1s - loss: 0.3366 - acc: 0.8407\n",
      "Epoch 7/250\n",
      " - 1s - loss: 0.3300 - acc: 0.8468\n",
      "Epoch 8/250\n",
      " - 1s - loss: 0.3261 - acc: 0.8486\n",
      "Epoch 9/250\n",
      " - 1s - loss: 0.3216 - acc: 0.8492\n",
      "Epoch 10/250\n",
      " - 1s - loss: 0.3194 - acc: 0.8524\n",
      "Epoch 11/250\n",
      " - 1s - loss: 0.3145 - acc: 0.8576\n",
      "Epoch 12/250\n",
      " - 1s - loss: 0.3137 - acc: 0.8559\n",
      "Epoch 13/250\n",
      " - 1s - loss: 0.3085 - acc: 0.8609\n",
      "Epoch 14/250\n",
      " - 1s - loss: 0.3055 - acc: 0.8618\n",
      "Epoch 15/250\n",
      " - 1s - loss: 0.3038 - acc: 0.8644\n",
      "Epoch 16/250\n",
      " - 1s - loss: 0.3051 - acc: 0.8625\n",
      "Epoch 17/250\n",
      " - 0s - loss: 0.2978 - acc: 0.8678\n",
      "Epoch 18/250\n",
      " - 1s - loss: 0.2980 - acc: 0.8664\n",
      "Epoch 19/250\n",
      " - 1s - loss: 0.2982 - acc: 0.8661\n",
      "Epoch 20/250\n",
      " - 1s - loss: 0.2969 - acc: 0.8672\n",
      "Epoch 21/250\n",
      " - 1s - loss: 0.2980 - acc: 0.8687\n",
      "Epoch 22/250\n",
      " - 1s - loss: 0.2918 - acc: 0.8711\n",
      "Epoch 23/250\n",
      " - 0s - loss: 0.2919 - acc: 0.8716\n",
      "Epoch 24/250\n",
      " - 0s - loss: 0.2924 - acc: 0.8719\n",
      "Epoch 25/250\n",
      " - 1s - loss: 0.2911 - acc: 0.8725\n",
      "Epoch 26/250\n",
      " - 1s - loss: 0.2887 - acc: 0.8721\n",
      "Epoch 27/250\n",
      " - 1s - loss: 0.2887 - acc: 0.8757\n",
      "Epoch 28/250\n",
      " - 1s - loss: 0.2858 - acc: 0.8768\n",
      "Epoch 29/250\n",
      " - 1s - loss: 0.2866 - acc: 0.8756\n",
      "Epoch 30/250\n",
      " - 1s - loss: 0.2887 - acc: 0.8698\n",
      "Epoch 31/250\n",
      " - 1s - loss: 0.2856 - acc: 0.8789\n",
      "Epoch 32/250\n",
      " - 1s - loss: 0.2847 - acc: 0.8780\n",
      "Epoch 33/250\n",
      " - 1s - loss: 0.2826 - acc: 0.8776\n",
      "Epoch 34/250\n",
      " - 1s - loss: 0.2815 - acc: 0.8774\n",
      "Epoch 35/250\n",
      " - 1s - loss: 0.2819 - acc: 0.8771\n",
      "Epoch 36/250\n",
      " - 1s - loss: 0.2785 - acc: 0.8821\n",
      "Epoch 37/250\n",
      " - 0s - loss: 0.2786 - acc: 0.8811\n",
      "Epoch 38/250\n",
      " - 0s - loss: 0.2825 - acc: 0.8780\n",
      "Epoch 39/250\n",
      " - 0s - loss: 0.2754 - acc: 0.8826\n",
      "Epoch 40/250\n",
      " - 1s - loss: 0.2780 - acc: 0.8797\n",
      "Epoch 41/250\n",
      " - 0s - loss: 0.2760 - acc: 0.8815\n",
      "Epoch 42/250\n",
      " - 0s - loss: 0.2764 - acc: 0.8835\n",
      "Epoch 43/250\n",
      " - 0s - loss: 0.2727 - acc: 0.8827\n",
      "Epoch 44/250\n",
      " - 1s - loss: 0.2754 - acc: 0.8817\n",
      "Epoch 45/250\n",
      " - 0s - loss: 0.2739 - acc: 0.8814\n",
      "Epoch 46/250\n",
      " - 0s - loss: 0.2723 - acc: 0.8840\n",
      "Epoch 47/250\n",
      " - 0s - loss: 0.2731 - acc: 0.8808\n",
      "Epoch 48/250\n",
      " - 0s - loss: 0.2726 - acc: 0.8833\n",
      "Epoch 49/250\n",
      " - 1s - loss: 0.2713 - acc: 0.8847\n",
      "Epoch 50/250\n",
      " - 0s - loss: 0.2705 - acc: 0.8847\n",
      "Epoch 51/250\n",
      " - 1s - loss: 0.2687 - acc: 0.8858\n",
      "Epoch 52/250\n",
      " - 0s - loss: 0.2689 - acc: 0.8840\n",
      "Epoch 53/250\n",
      " - 1s - loss: 0.2681 - acc: 0.8837\n",
      "Epoch 54/250\n",
      " - 0s - loss: 0.2672 - acc: 0.8858\n",
      "Epoch 55/250\n",
      " - 0s - loss: 0.2663 - acc: 0.8867\n",
      "Epoch 56/250\n",
      " - 0s - loss: 0.2648 - acc: 0.8862\n",
      "Epoch 57/250\n",
      " - 1s - loss: 0.2663 - acc: 0.8867\n",
      "Epoch 58/250\n",
      " - 0s - loss: 0.2652 - acc: 0.8861\n",
      "Epoch 59/250\n",
      " - 0s - loss: 0.2663 - acc: 0.8856\n",
      "Epoch 60/250\n",
      " - 0s - loss: 0.2616 - acc: 0.8876\n",
      "Epoch 61/250\n",
      " - 1s - loss: 0.2633 - acc: 0.8887\n",
      "Epoch 62/250\n",
      " - 0s - loss: 0.2644 - acc: 0.8869\n",
      "Epoch 63/250\n",
      " - 0s - loss: 0.2612 - acc: 0.8876\n",
      "Epoch 64/250\n",
      " - 0s - loss: 0.2612 - acc: 0.8879\n",
      "Epoch 65/250\n",
      " - 1s - loss: 0.2638 - acc: 0.8866\n",
      "Epoch 66/250\n",
      " - 0s - loss: 0.2597 - acc: 0.8882\n",
      "Epoch 67/250\n",
      " - 0s - loss: 0.2583 - acc: 0.8890\n",
      "Epoch 68/250\n",
      " - 0s - loss: 0.2600 - acc: 0.8873\n",
      "Epoch 69/250\n",
      " - 0s - loss: 0.2611 - acc: 0.8878\n",
      "Epoch 70/250\n",
      " - 1s - loss: 0.2610 - acc: 0.8872\n",
      "Epoch 71/250\n",
      " - 1s - loss: 0.2557 - acc: 0.8923\n",
      "Epoch 72/250\n",
      " - 0s - loss: 0.2596 - acc: 0.8887\n",
      "Epoch 73/250\n",
      " - 0s - loss: 0.2551 - acc: 0.8901\n",
      "Epoch 74/250\n",
      " - 1s - loss: 0.2569 - acc: 0.8916\n",
      "Epoch 75/250\n",
      " - 0s - loss: 0.2537 - acc: 0.8936\n",
      "Epoch 76/250\n",
      " - 0s - loss: 0.2564 - acc: 0.8872\n",
      "Epoch 77/250\n",
      " - 0s - loss: 0.2531 - acc: 0.8899\n",
      "Epoch 78/250\n",
      " - 1s - loss: 0.2557 - acc: 0.8875\n",
      "Epoch 79/250\n",
      " - 0s - loss: 0.2523 - acc: 0.8911\n",
      "Epoch 80/250\n",
      " - 0s - loss: 0.2512 - acc: 0.8917\n",
      "Epoch 81/250\n",
      " - 0s - loss: 0.2539 - acc: 0.8910\n",
      "Epoch 82/250\n",
      " - 1s - loss: 0.2577 - acc: 0.8864\n",
      "Epoch 83/250\n",
      " - 0s - loss: 0.2532 - acc: 0.8933\n",
      "Epoch 84/250\n",
      " - 0s - loss: 0.2501 - acc: 0.8927\n",
      "Epoch 85/250\n",
      " - 0s - loss: 0.2487 - acc: 0.8930\n",
      "Epoch 86/250\n",
      " - 1s - loss: 0.2484 - acc: 0.8963\n",
      "Epoch 87/250\n",
      " - 0s - loss: 0.2501 - acc: 0.8919\n",
      "Epoch 88/250\n",
      " - 0s - loss: 0.2521 - acc: 0.8919\n",
      "Epoch 89/250\n",
      " - 0s - loss: 0.2475 - acc: 0.8937\n",
      "Epoch 90/250\n",
      " - 0s - loss: 0.2470 - acc: 0.8940\n",
      "Epoch 91/250\n",
      " - 1s - loss: 0.2474 - acc: 0.8952\n",
      "Epoch 92/250\n",
      " - 1s - loss: 0.2488 - acc: 0.8911\n",
      "Epoch 93/250\n",
      " - 1s - loss: 0.2481 - acc: 0.8936\n",
      "Epoch 94/250\n",
      " - 1s - loss: 0.2472 - acc: 0.8943\n",
      "Epoch 95/250\n",
      " - 0s - loss: 0.2484 - acc: 0.8920\n",
      "Epoch 96/250\n",
      " - 0s - loss: 0.2462 - acc: 0.8940\n",
      "Epoch 97/250\n",
      " - 0s - loss: 0.2438 - acc: 0.8948\n",
      "Epoch 98/250\n",
      " - 1s - loss: 0.2514 - acc: 0.8899\n",
      "Epoch 99/250\n",
      " - 0s - loss: 0.2420 - acc: 0.8974\n",
      "Epoch 100/250\n",
      " - 0s - loss: 0.2435 - acc: 0.8962\n",
      "Epoch 101/250\n",
      " - 0s - loss: 0.2440 - acc: 0.8968\n",
      "Epoch 102/250\n",
      " - 0s - loss: 0.2452 - acc: 0.8933\n",
      "Epoch 103/250\n",
      " - 1s - loss: 0.2432 - acc: 0.8942\n",
      "Epoch 104/250\n",
      " - 1s - loss: 0.2423 - acc: 0.8968\n",
      "Epoch 105/250\n",
      " - 1s - loss: 0.2426 - acc: 0.8954\n",
      "Epoch 106/250\n",
      " - 1s - loss: 0.2421 - acc: 0.8949\n",
      "Epoch 107/250\n",
      " - 0s - loss: 0.2474 - acc: 0.8936\n",
      "Epoch 108/250\n",
      " - 1s - loss: 0.2421 - acc: 0.8957\n",
      "Epoch 109/250\n",
      " - 0s - loss: 0.2460 - acc: 0.8920\n",
      "Epoch 110/250\n",
      " - 1s - loss: 0.2444 - acc: 0.8925\n",
      "Epoch 111/250\n",
      " - 1s - loss: 0.2408 - acc: 0.8946\n",
      "Epoch 112/250\n",
      " - 0s - loss: 0.2400 - acc: 0.8975\n",
      "Epoch 113/250\n",
      " - 0s - loss: 0.2421 - acc: 0.8959\n",
      "Epoch 114/250\n",
      " - 1s - loss: 0.2396 - acc: 0.8969\n",
      "Epoch 115/250\n",
      " - 0s - loss: 0.2421 - acc: 0.8937\n",
      "Epoch 116/250\n",
      " - 0s - loss: 0.2382 - acc: 0.8972\n",
      "Epoch 117/250\n",
      " - 0s - loss: 0.2451 - acc: 0.8939\n",
      "Epoch 118/250\n",
      " - 0s - loss: 0.2419 - acc: 0.8945\n",
      "Epoch 119/250\n",
      " - 1s - loss: 0.2399 - acc: 0.8975\n",
      "Epoch 120/250\n",
      " - 0s - loss: 0.2380 - acc: 0.8991\n",
      "Epoch 121/250\n",
      " - 0s - loss: 0.2365 - acc: 0.8980\n",
      "Epoch 122/250\n",
      " - 0s - loss: 0.2422 - acc: 0.8917\n",
      "Epoch 123/250\n",
      " - 1s - loss: 0.2395 - acc: 0.9000\n",
      "Epoch 124/250\n",
      " - 0s - loss: 0.2355 - acc: 0.8978\n",
      "Epoch 125/250\n",
      " - 0s - loss: 0.2390 - acc: 0.8966\n",
      "Epoch 126/250\n",
      " - 0s - loss: 0.2400 - acc: 0.8927\n",
      "Epoch 127/250\n",
      " - 1s - loss: 0.2361 - acc: 0.8992\n",
      "Epoch 128/250\n",
      " - 0s - loss: 0.2364 - acc: 0.9001\n",
      "Epoch 129/250\n",
      " - 0s - loss: 0.2361 - acc: 0.8972\n",
      "Epoch 130/250\n",
      " - 0s - loss: 0.2371 - acc: 0.8987\n",
      "Epoch 131/250\n",
      " - 1s - loss: 0.2371 - acc: 0.8998\n",
      "Epoch 132/250\n",
      " - 1s - loss: 0.2352 - acc: 0.8974\n",
      "Epoch 133/250\n",
      " - 0s - loss: 0.2362 - acc: 0.8975\n",
      "Epoch 134/250\n",
      " - 0s - loss: 0.2362 - acc: 0.8968\n",
      "Epoch 135/250\n",
      " - 0s - loss: 0.2378 - acc: 0.8951\n",
      "Epoch 136/250\n",
      " - 1s - loss: 0.2352 - acc: 0.8981\n",
      "Epoch 137/250\n",
      " - 0s - loss: 0.2367 - acc: 0.9007\n",
      "Epoch 138/250\n",
      " - 0s - loss: 0.2360 - acc: 0.8987\n",
      "Epoch 139/250\n",
      " - 0s - loss: 0.2326 - acc: 0.9026\n",
      "Epoch 140/250\n",
      " - 1s - loss: 0.2322 - acc: 0.9015\n",
      "Epoch 141/250\n",
      " - 0s - loss: 0.2348 - acc: 0.8983\n",
      "Epoch 142/250\n",
      " - 0s - loss: 0.2339 - acc: 0.8995\n",
      "Epoch 143/250\n",
      " - 0s - loss: 0.2378 - acc: 0.8937\n",
      "Epoch 144/250\n",
      " - 1s - loss: 0.2351 - acc: 0.9000\n",
      "Epoch 145/250\n",
      " - 0s - loss: 0.2323 - acc: 0.9006\n",
      "Epoch 146/250\n",
      " - 0s - loss: 0.2324 - acc: 0.8983\n",
      "Epoch 147/250\n",
      " - 0s - loss: 0.2351 - acc: 0.8971\n",
      "Epoch 148/250\n",
      " - 1s - loss: 0.2339 - acc: 0.8974\n",
      "Epoch 149/250\n",
      " - 0s - loss: 0.2303 - acc: 0.8995\n",
      "Epoch 150/250\n",
      " - 0s - loss: 0.2328 - acc: 0.9006\n",
      "Epoch 151/250\n",
      " - 0s - loss: 0.2340 - acc: 0.8987\n",
      "Epoch 152/250\n",
      " - 1s - loss: 0.2312 - acc: 0.9000\n",
      "Epoch 153/250\n",
      " - 0s - loss: 0.2336 - acc: 0.8983\n",
      "Epoch 154/250\n",
      " - 0s - loss: 0.2332 - acc: 0.9024\n",
      "Epoch 155/250\n",
      " - 0s - loss: 0.2343 - acc: 0.8981\n",
      "Epoch 156/250\n",
      " - 0s - loss: 0.2333 - acc: 0.8981\n",
      "Epoch 157/250\n",
      " - 1s - loss: 0.2362 - acc: 0.8978\n",
      "Epoch 158/250\n",
      " - 0s - loss: 0.2315 - acc: 0.9000\n",
      "Epoch 159/250\n",
      " - 0s - loss: 0.2317 - acc: 0.9001\n",
      "Epoch 160/250\n",
      " - 0s - loss: 0.2281 - acc: 0.9007\n",
      "Epoch 161/250\n",
      " - 1s - loss: 0.2363 - acc: 0.8975\n",
      "Epoch 162/250\n",
      " - 1s - loss: 0.2323 - acc: 0.8986\n",
      "Epoch 163/250\n",
      " - 1s - loss: 0.2319 - acc: 0.8984\n",
      "Epoch 164/250\n",
      " - 1s - loss: 0.2318 - acc: 0.8998\n",
      "Epoch 165/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2322 - acc: 0.8975\n",
      "Epoch 166/250\n",
      " - 0s - loss: 0.2323 - acc: 0.8987\n",
      "Epoch 167/250\n",
      " - 0s - loss: 0.2281 - acc: 0.9016\n",
      "Epoch 168/250\n",
      " - 1s - loss: 0.2269 - acc: 0.9016\n",
      "Epoch 169/250\n",
      " - 0s - loss: 0.2297 - acc: 0.9015\n",
      "Epoch 170/250\n",
      " - 1s - loss: 0.2281 - acc: 0.9033\n",
      "Epoch 171/250\n",
      " - 1s - loss: 0.2310 - acc: 0.9003\n",
      "Epoch 172/250\n",
      " - 1s - loss: 0.2285 - acc: 0.9000\n",
      "Epoch 173/250\n",
      " - 0s - loss: 0.2270 - acc: 0.9039\n",
      "Epoch 174/250\n",
      " - 1s - loss: 0.2295 - acc: 0.8978\n",
      "Epoch 175/250\n",
      " - 1s - loss: 0.2298 - acc: 0.9001\n",
      "Epoch 176/250\n",
      " - 1s - loss: 0.2299 - acc: 0.9003\n",
      "Epoch 177/250\n",
      " - 1s - loss: 0.2269 - acc: 0.9041\n",
      "Epoch 178/250\n",
      " - 0s - loss: 0.2269 - acc: 0.9032\n",
      "Epoch 179/250\n",
      " - 0s - loss: 0.2273 - acc: 0.9029\n",
      "Epoch 180/250\n",
      " - 1s - loss: 0.2292 - acc: 0.8997\n",
      "Epoch 181/250\n",
      " - 0s - loss: 0.2269 - acc: 0.9013\n",
      "Epoch 182/250\n",
      " - 0s - loss: 0.2272 - acc: 0.9030\n",
      "Epoch 183/250\n",
      " - 0s - loss: 0.2270 - acc: 0.9023\n",
      "Epoch 184/250\n",
      " - 1s - loss: 0.2260 - acc: 0.9053\n",
      "Epoch 185/250\n",
      " - 0s - loss: 0.2275 - acc: 0.9007\n",
      "Epoch 186/250\n",
      " - 0s - loss: 0.2265 - acc: 0.9029\n",
      "Epoch 187/250\n",
      " - 0s - loss: 0.2270 - acc: 0.9016\n",
      "Epoch 188/250\n",
      " - 1s - loss: 0.2284 - acc: 0.9012\n",
      "Epoch 189/250\n",
      " - 0s - loss: 0.2260 - acc: 0.9021\n",
      "Epoch 190/250\n",
      " - 1s - loss: 0.2295 - acc: 0.9020\n",
      "Epoch 191/250\n",
      " - 1s - loss: 0.2285 - acc: 0.9000\n",
      "Epoch 192/250\n",
      " - 0s - loss: 0.2253 - acc: 0.9013\n",
      "Epoch 193/250\n",
      " - 0s - loss: 0.2244 - acc: 0.9029\n",
      "Epoch 194/250\n",
      " - 0s - loss: 0.2281 - acc: 0.8984\n",
      "Epoch 195/250\n",
      " - 0s - loss: 0.2285 - acc: 0.9026\n",
      "Epoch 196/250\n",
      " - 1s - loss: 0.2250 - acc: 0.9035\n",
      "Epoch 197/250\n",
      " - 0s - loss: 0.2246 - acc: 0.9030\n",
      "Epoch 198/250\n",
      " - 0s - loss: 0.2253 - acc: 0.9041\n",
      "Epoch 199/250\n",
      " - 0s - loss: 0.2218 - acc: 0.9050\n",
      "Epoch 200/250\n",
      " - 1s - loss: 0.2269 - acc: 0.9029\n",
      "Epoch 201/250\n",
      " - 0s - loss: 0.2248 - acc: 0.8994\n",
      "Epoch 202/250\n",
      " - 0s - loss: 0.2223 - acc: 0.9058\n",
      "Epoch 203/250\n",
      " - 0s - loss: 0.2241 - acc: 0.9030\n",
      "Epoch 204/250\n",
      " - 1s - loss: 0.2261 - acc: 0.9021\n",
      "Epoch 205/250\n",
      " - 0s - loss: 0.2243 - acc: 0.9012\n",
      "Epoch 206/250\n",
      " - 0s - loss: 0.2243 - acc: 0.9065\n",
      "Epoch 207/250\n",
      " - 0s - loss: 0.2241 - acc: 0.9020\n",
      "Epoch 208/250\n",
      " - 1s - loss: 0.2240 - acc: 0.8995\n",
      "Epoch 209/250\n",
      " - 0s - loss: 0.2256 - acc: 0.8998\n",
      "Epoch 210/250\n",
      " - 0s - loss: 0.2219 - acc: 0.9009\n",
      "Epoch 211/250\n",
      " - 0s - loss: 0.2238 - acc: 0.9024\n",
      "Epoch 212/250\n",
      " - 0s - loss: 0.2228 - acc: 0.9018\n",
      "Epoch 213/250\n",
      " - 1s - loss: 0.2231 - acc: 0.9042\n",
      "Epoch 214/250\n",
      " - 0s - loss: 0.2229 - acc: 0.9033\n",
      "Epoch 215/250\n",
      " - 0s - loss: 0.2252 - acc: 0.9009\n",
      "Epoch 216/250\n",
      " - 0s - loss: 0.2214 - acc: 0.9042\n",
      "Epoch 217/250\n",
      " - 1s - loss: 0.2223 - acc: 0.9021\n",
      "Epoch 218/250\n",
      " - 0s - loss: 0.2246 - acc: 0.9010\n",
      "Epoch 219/250\n",
      " - 0s - loss: 0.2229 - acc: 0.9047\n",
      "Epoch 220/250\n",
      " - 0s - loss: 0.2208 - acc: 0.9067\n",
      "Epoch 221/250\n",
      " - 1s - loss: 0.2214 - acc: 0.9047\n",
      "Epoch 222/250\n",
      " - 0s - loss: 0.2217 - acc: 0.9042\n",
      "Epoch 223/250\n",
      " - 0s - loss: 0.2229 - acc: 0.9027\n",
      "Epoch 224/250\n",
      " - 0s - loss: 0.2203 - acc: 0.9020\n",
      "Epoch 225/250\n",
      " - 1s - loss: 0.2224 - acc: 0.9038\n",
      "Epoch 226/250\n",
      " - 1s - loss: 0.2194 - acc: 0.9050\n",
      "Epoch 227/250\n",
      " - 0s - loss: 0.2236 - acc: 0.9059\n",
      "Epoch 228/250\n",
      " - 0s - loss: 0.2228 - acc: 0.9021\n",
      "Epoch 229/250\n",
      " - 0s - loss: 0.2197 - acc: 0.9071\n",
      "Epoch 230/250\n",
      " - 1s - loss: 0.2211 - acc: 0.9027\n",
      "Epoch 231/250\n",
      " - 1s - loss: 0.2225 - acc: 0.9036\n",
      "Epoch 232/250\n",
      " - 0s - loss: 0.2219 - acc: 0.9015\n",
      "Epoch 233/250\n",
      " - 0s - loss: 0.2206 - acc: 0.9032\n",
      "Epoch 234/250\n",
      " - 1s - loss: 0.2201 - acc: 0.9055\n",
      "Epoch 235/250\n",
      " - 0s - loss: 0.2211 - acc: 0.9041\n",
      "Epoch 236/250\n",
      " - 0s - loss: 0.2224 - acc: 0.9035\n",
      "Epoch 237/250\n",
      " - 0s - loss: 0.2232 - acc: 0.9035\n",
      "Epoch 238/250\n",
      " - 1s - loss: 0.2188 - acc: 0.9041\n",
      "Epoch 239/250\n",
      " - 0s - loss: 0.2197 - acc: 0.9029\n",
      "Epoch 240/250\n",
      " - 0s - loss: 0.2226 - acc: 0.9039\n",
      "Epoch 241/250\n",
      " - 0s - loss: 0.2218 - acc: 0.9048\n",
      "Epoch 242/250\n",
      " - 1s - loss: 0.2182 - acc: 0.9071\n",
      "Epoch 243/250\n",
      " - 1s - loss: 0.2210 - acc: 0.9062\n",
      "Epoch 244/250\n",
      " - 0s - loss: 0.2211 - acc: 0.9048\n",
      "Epoch 245/250\n",
      " - 0s - loss: 0.2190 - acc: 0.9068\n",
      "Epoch 246/250\n",
      " - 0s - loss: 0.2172 - acc: 0.9053\n",
      "Epoch 247/250\n",
      " - 1s - loss: 0.2162 - acc: 0.9113\n",
      "Epoch 248/250\n",
      " - 0s - loss: 0.2161 - acc: 0.9053\n",
      "Epoch 249/250\n",
      " - 0s - loss: 0.2183 - acc: 0.9059\n",
      "Epoch 250/250\n",
      " - 0s - loss: 0.2165 - acc: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4f07e780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    one_hot_y_train,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=100, activation='relu', input_dim=40))\n",
    "deep_model.add(Dense(units=100, activation='relu'))\n",
    "deep_model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 14,503\n",
      "Trainable params: 14,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " - 1s - loss: 0.5112 - acc: 0.7540\n",
      "Epoch 2/250\n",
      " - 1s - loss: 0.3628 - acc: 0.8068\n",
      "Epoch 3/250\n",
      " - 1s - loss: 0.3464 - acc: 0.8262\n",
      "Epoch 4/250\n",
      " - 1s - loss: 0.3404 - acc: 0.8358\n",
      "Epoch 5/250\n",
      " - 1s - loss: 0.3362 - acc: 0.8317\n",
      "Epoch 6/250\n",
      " - 1s - loss: 0.3238 - acc: 0.8474\n",
      "Epoch 7/250\n",
      " - 1s - loss: 0.3223 - acc: 0.8457\n",
      "Epoch 8/250\n",
      " - 1s - loss: 0.3157 - acc: 0.8507\n",
      "Epoch 9/250\n",
      " - 1s - loss: 0.3104 - acc: 0.8591\n",
      "Epoch 10/250\n",
      " - 1s - loss: 0.3084 - acc: 0.8590\n",
      "Epoch 11/250\n",
      " - 1s - loss: 0.3078 - acc: 0.8596\n",
      "Epoch 12/250\n",
      " - 1s - loss: 0.3018 - acc: 0.8594\n",
      "Epoch 13/250\n",
      " - 1s - loss: 0.2995 - acc: 0.8664\n",
      "Epoch 14/250\n",
      " - 1s - loss: 0.2970 - acc: 0.8690\n",
      "Epoch 15/250\n",
      " - 1s - loss: 0.2966 - acc: 0.8679\n",
      "Epoch 16/250\n",
      " - 1s - loss: 0.2901 - acc: 0.8692\n",
      "Epoch 17/250\n",
      " - 1s - loss: 0.2880 - acc: 0.8751\n",
      "Epoch 18/250\n",
      " - 1s - loss: 0.2852 - acc: 0.8771\n",
      "Epoch 19/250\n",
      " - 1s - loss: 0.2855 - acc: 0.8719\n",
      "Epoch 20/250\n",
      " - 1s - loss: 0.2786 - acc: 0.8803\n",
      "Epoch 21/250\n",
      " - 1s - loss: 0.2812 - acc: 0.8763\n",
      "Epoch 22/250\n",
      " - 1s - loss: 0.2801 - acc: 0.8766\n",
      "Epoch 23/250\n",
      " - 1s - loss: 0.2741 - acc: 0.8830\n",
      "Epoch 24/250\n",
      " - 1s - loss: 0.2823 - acc: 0.8756\n",
      "Epoch 25/250\n",
      " - 1s - loss: 0.2743 - acc: 0.8801\n",
      "Epoch 26/250\n",
      " - 1s - loss: 0.2780 - acc: 0.8776\n",
      "Epoch 27/250\n",
      " - 1s - loss: 0.2676 - acc: 0.8835\n",
      "Epoch 28/250\n",
      " - 1s - loss: 0.2689 - acc: 0.8832\n",
      "Epoch 29/250\n",
      " - 1s - loss: 0.2727 - acc: 0.8791\n",
      "Epoch 30/250\n",
      " - 1s - loss: 0.2636 - acc: 0.8856\n",
      "Epoch 31/250\n",
      " - 1s - loss: 0.2668 - acc: 0.8859\n",
      "Epoch 32/250\n",
      " - 1s - loss: 0.2617 - acc: 0.8853\n",
      "Epoch 33/250\n",
      " - 1s - loss: 0.2582 - acc: 0.8887\n",
      "Epoch 34/250\n",
      " - 1s - loss: 0.2628 - acc: 0.8827\n",
      "Epoch 35/250\n",
      " - 1s - loss: 0.2603 - acc: 0.8856\n",
      "Epoch 36/250\n",
      " - 1s - loss: 0.2591 - acc: 0.8856\n",
      "Epoch 37/250\n",
      " - 1s - loss: 0.2592 - acc: 0.8881\n",
      "Epoch 38/250\n",
      " - 1s - loss: 0.2580 - acc: 0.8904\n",
      "Epoch 39/250\n",
      " - 1s - loss: 0.2565 - acc: 0.8901\n",
      "Epoch 40/250\n",
      " - 1s - loss: 0.2512 - acc: 0.8925\n",
      "Epoch 41/250\n",
      " - 1s - loss: 0.2515 - acc: 0.8905\n",
      "Epoch 42/250\n",
      " - 1s - loss: 0.2491 - acc: 0.8914\n",
      "Epoch 43/250\n",
      " - 1s - loss: 0.2539 - acc: 0.8904\n",
      "Epoch 44/250\n",
      " - 1s - loss: 0.2514 - acc: 0.8882\n",
      "Epoch 45/250\n",
      " - 1s - loss: 0.2496 - acc: 0.8940\n",
      "Epoch 46/250\n",
      " - 1s - loss: 0.2483 - acc: 0.8902\n",
      "Epoch 47/250\n",
      " - 1s - loss: 0.2466 - acc: 0.8928\n",
      "Epoch 48/250\n",
      " - 1s - loss: 0.2464 - acc: 0.8949\n",
      "Epoch 49/250\n",
      " - 1s - loss: 0.2455 - acc: 0.8913\n",
      "Epoch 50/250\n",
      " - 1s - loss: 0.2429 - acc: 0.8933\n",
      "Epoch 51/250\n",
      " - 1s - loss: 0.2466 - acc: 0.8888\n",
      "Epoch 52/250\n",
      " - 1s - loss: 0.2427 - acc: 0.8934\n",
      "Epoch 53/250\n",
      " - 1s - loss: 0.2430 - acc: 0.8937\n",
      "Epoch 54/250\n",
      " - 1s - loss: 0.2479 - acc: 0.8881\n",
      "Epoch 55/250\n",
      " - 1s - loss: 0.2446 - acc: 0.8939\n",
      "Epoch 56/250\n",
      " - 1s - loss: 0.2370 - acc: 0.8959\n",
      "Epoch 57/250\n",
      " - 1s - loss: 0.2446 - acc: 0.8940\n",
      "Epoch 58/250\n",
      " - 1s - loss: 0.2411 - acc: 0.8951\n",
      "Epoch 59/250\n",
      " - 1s - loss: 0.2421 - acc: 0.8951\n",
      "Epoch 60/250\n",
      " - 1s - loss: 0.2418 - acc: 0.8917\n",
      "Epoch 61/250\n",
      " - 1s - loss: 0.2342 - acc: 0.8992\n",
      "Epoch 62/250\n",
      " - 1s - loss: 0.2365 - acc: 0.9001\n",
      "Epoch 63/250\n",
      " - 1s - loss: 0.2365 - acc: 0.8962\n",
      "Epoch 64/250\n",
      " - 1s - loss: 0.2375 - acc: 0.8942\n",
      "Epoch 65/250\n",
      " - 1s - loss: 0.2321 - acc: 0.8998\n",
      "Epoch 66/250\n",
      " - 1s - loss: 0.2355 - acc: 0.8998\n",
      "Epoch 67/250\n",
      " - 1s - loss: 0.2347 - acc: 0.8969\n",
      "Epoch 68/250\n",
      " - 1s - loss: 0.2350 - acc: 0.8959\n",
      "Epoch 69/250\n",
      " - 1s - loss: 0.2333 - acc: 0.8949\n",
      "Epoch 70/250\n",
      " - 1s - loss: 0.2417 - acc: 0.8916\n",
      "Epoch 71/250\n",
      " - 1s - loss: 0.2333 - acc: 0.8952\n",
      "Epoch 72/250\n",
      " - 1s - loss: 0.2345 - acc: 0.8977\n",
      "Epoch 73/250\n",
      " - 1s - loss: 0.2267 - acc: 0.9018\n",
      "Epoch 74/250\n",
      " - 1s - loss: 0.2332 - acc: 0.8962\n",
      "Epoch 75/250\n",
      " - 1s - loss: 0.2262 - acc: 0.9012\n",
      "Epoch 76/250\n",
      " - 1s - loss: 0.2303 - acc: 0.8965\n",
      "Epoch 77/250\n",
      " - 1s - loss: 0.2267 - acc: 0.9006\n",
      "Epoch 78/250\n",
      " - 1s - loss: 0.2374 - acc: 0.8963\n",
      "Epoch 79/250\n",
      " - 1s - loss: 0.2276 - acc: 0.8987\n",
      "Epoch 80/250\n",
      " - 1s - loss: 0.2228 - acc: 0.9010\n",
      "Epoch 81/250\n",
      " - 1s - loss: 0.2247 - acc: 0.9044\n",
      "Epoch 82/250\n",
      " - 1s - loss: 0.2296 - acc: 0.8972\n",
      "Epoch 83/250\n",
      " - 1s - loss: 0.2295 - acc: 0.8987\n",
      "Epoch 84/250\n",
      " - 1s - loss: 0.2238 - acc: 0.9050\n",
      "Epoch 85/250\n",
      " - 1s - loss: 0.2248 - acc: 0.8984\n",
      "Epoch 86/250\n",
      " - 1s - loss: 0.2232 - acc: 0.9033\n",
      "Epoch 87/250\n",
      " - 1s - loss: 0.2250 - acc: 0.8987\n",
      "Epoch 88/250\n",
      " - 1s - loss: 0.2204 - acc: 0.9015\n",
      "Epoch 89/250\n",
      " - 1s - loss: 0.2251 - acc: 0.9013\n",
      "Epoch 90/250\n",
      " - 1s - loss: 0.2315 - acc: 0.8951\n",
      "Epoch 91/250\n",
      " - 1s - loss: 0.2278 - acc: 0.9013\n",
      "Epoch 92/250\n",
      " - 1s - loss: 0.2221 - acc: 0.9030\n",
      "Epoch 93/250\n",
      " - 1s - loss: 0.2193 - acc: 0.9015\n",
      "Epoch 94/250\n",
      " - 1s - loss: 0.2206 - acc: 0.8998\n",
      "Epoch 95/250\n",
      " - 1s - loss: 0.2290 - acc: 0.8969\n",
      "Epoch 96/250\n",
      " - 1s - loss: 0.2202 - acc: 0.9032\n",
      "Epoch 97/250\n",
      " - 1s - loss: 0.2202 - acc: 0.9036\n",
      "Epoch 98/250\n",
      " - 1s - loss: 0.2192 - acc: 0.9033\n",
      "Epoch 99/250\n",
      " - 1s - loss: 0.2165 - acc: 0.9047\n",
      "Epoch 100/250\n",
      " - 1s - loss: 0.2176 - acc: 0.9053\n",
      "Epoch 101/250\n",
      " - 1s - loss: 0.2192 - acc: 0.9030\n",
      "Epoch 102/250\n",
      " - 1s - loss: 0.2191 - acc: 0.9013\n",
      "Epoch 103/250\n",
      " - 1s - loss: 0.2179 - acc: 0.9024\n",
      "Epoch 104/250\n",
      " - 1s - loss: 0.2190 - acc: 0.9033\n",
      "Epoch 105/250\n",
      " - 1s - loss: 0.2182 - acc: 0.9036\n",
      "Epoch 106/250\n",
      " - 1s - loss: 0.2139 - acc: 0.9053\n",
      "Epoch 107/250\n",
      " - 1s - loss: 0.2094 - acc: 0.9077\n",
      "Epoch 108/250\n",
      " - 1s - loss: 0.2145 - acc: 0.9026\n",
      "Epoch 109/250\n",
      " - 1s - loss: 0.2110 - acc: 0.9082\n",
      "Epoch 110/250\n",
      " - 1s - loss: 0.2126 - acc: 0.9084\n",
      "Epoch 111/250\n",
      " - 1s - loss: 0.2145 - acc: 0.9038\n",
      "Epoch 112/250\n",
      " - 1s - loss: 0.2096 - acc: 0.9061\n",
      "Epoch 113/250\n",
      " - 1s - loss: 0.2165 - acc: 0.9018\n",
      "Epoch 114/250\n",
      " - 1s - loss: 0.2113 - acc: 0.9067\n",
      "Epoch 115/250\n",
      " - 1s - loss: 0.2118 - acc: 0.9062\n",
      "Epoch 116/250\n",
      " - 1s - loss: 0.2124 - acc: 0.9048\n",
      "Epoch 117/250\n",
      " - 1s - loss: 0.2072 - acc: 0.9113\n",
      "Epoch 118/250\n",
      " - 1s - loss: 0.2173 - acc: 0.9007\n",
      "Epoch 119/250\n",
      " - 1s - loss: 0.2112 - acc: 0.9042\n",
      "Epoch 120/250\n",
      " - 1s - loss: 0.2122 - acc: 0.9067\n",
      "Epoch 121/250\n",
      " - 1s - loss: 0.2089 - acc: 0.9079\n",
      "Epoch 122/250\n",
      " - 1s - loss: 0.2124 - acc: 0.9087\n",
      "Epoch 123/250\n",
      " - 1s - loss: 0.2126 - acc: 0.9035\n",
      "Epoch 124/250\n",
      " - 1s - loss: 0.2093 - acc: 0.9062\n",
      "Epoch 125/250\n",
      " - 1s - loss: 0.2115 - acc: 0.9077\n",
      "Epoch 126/250\n",
      " - 1s - loss: 0.2091 - acc: 0.9077\n",
      "Epoch 127/250\n",
      " - 1s - loss: 0.2121 - acc: 0.9077\n",
      "Epoch 128/250\n",
      " - 1s - loss: 0.2124 - acc: 0.9056\n",
      "Epoch 129/250\n",
      " - 1s - loss: 0.2096 - acc: 0.9074\n",
      "Epoch 130/250\n",
      " - 1s - loss: 0.2036 - acc: 0.9125\n",
      "Epoch 131/250\n",
      " - 1s - loss: 0.2083 - acc: 0.9090\n",
      "Epoch 132/250\n",
      " - 1s - loss: 0.2023 - acc: 0.9109\n",
      "Epoch 133/250\n",
      " - 1s - loss: 0.2024 - acc: 0.9131\n",
      "Epoch 134/250\n",
      " - 1s - loss: 0.2060 - acc: 0.9090\n",
      "Epoch 135/250\n",
      " - 1s - loss: 0.2014 - acc: 0.9131\n",
      "Epoch 136/250\n",
      " - 1s - loss: 0.2018 - acc: 0.9109\n",
      "Epoch 137/250\n",
      " - 1s - loss: 0.2055 - acc: 0.9061\n",
      "Epoch 138/250\n",
      " - 1s - loss: 0.2047 - acc: 0.9125\n",
      "Epoch 139/250\n",
      " - 1s - loss: 0.2044 - acc: 0.9091\n",
      "Epoch 140/250\n",
      " - 1s - loss: 0.2017 - acc: 0.9146\n",
      "Epoch 141/250\n",
      " - 1s - loss: 0.2087 - acc: 0.9048\n",
      "Epoch 142/250\n",
      " - 1s - loss: 0.2016 - acc: 0.9128\n",
      "Epoch 143/250\n",
      " - 1s - loss: 0.2018 - acc: 0.9113\n",
      "Epoch 144/250\n",
      " - 1s - loss: 0.2002 - acc: 0.9100\n",
      "Epoch 145/250\n",
      " - 1s - loss: 0.1986 - acc: 0.9126\n",
      "Epoch 146/250\n",
      " - 1s - loss: 0.2025 - acc: 0.9122\n",
      "Epoch 147/250\n",
      " - 1s - loss: 0.1965 - acc: 0.9102\n",
      "Epoch 148/250\n",
      " - 1s - loss: 0.2001 - acc: 0.9145\n",
      "Epoch 149/250\n",
      " - 1s - loss: 0.1986 - acc: 0.9106\n",
      "Epoch 150/250\n",
      " - 1s - loss: 0.1974 - acc: 0.9138\n",
      "Epoch 151/250\n",
      " - 1s - loss: 0.1970 - acc: 0.9119\n",
      "Epoch 152/250\n",
      " - 1s - loss: 0.1973 - acc: 0.9140\n",
      "Epoch 153/250\n",
      " - 1s - loss: 0.2009 - acc: 0.9109\n",
      "Epoch 154/250\n",
      " - 1s - loss: 0.2040 - acc: 0.9119\n",
      "Epoch 155/250\n",
      " - 1s - loss: 0.1998 - acc: 0.9126\n",
      "Epoch 156/250\n",
      " - 1s - loss: 0.2015 - acc: 0.9077\n",
      "Epoch 157/250\n",
      " - 1s - loss: 0.1964 - acc: 0.9138\n",
      "Epoch 158/250\n",
      " - 1s - loss: 0.1996 - acc: 0.9119\n",
      "Epoch 159/250\n",
      " - 1s - loss: 0.1948 - acc: 0.9100\n",
      "Epoch 160/250\n",
      " - 1s - loss: 0.1947 - acc: 0.9126\n",
      "Epoch 161/250\n",
      " - 1s - loss: 0.1944 - acc: 0.9122\n",
      "Epoch 162/250\n",
      " - 1s - loss: 0.1910 - acc: 0.9135\n",
      "Epoch 163/250\n",
      " - 1s - loss: 0.1971 - acc: 0.9111\n",
      "Epoch 164/250\n",
      " - 1s - loss: 0.1935 - acc: 0.9116\n",
      "Epoch 165/250\n",
      " - 1s - loss: 0.1970 - acc: 0.9123\n",
      "Epoch 166/250\n",
      " - 1s - loss: 0.1942 - acc: 0.9119\n",
      "Epoch 167/250\n",
      " - 1s - loss: 0.1929 - acc: 0.9145\n",
      "Epoch 168/250\n",
      " - 1s - loss: 0.1959 - acc: 0.9142\n",
      "Epoch 169/250\n",
      " - 1s - loss: 0.1946 - acc: 0.9125\n",
      "Epoch 170/250\n",
      " - 1s - loss: 0.1893 - acc: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/250\n",
      " - 1s - loss: 0.1902 - acc: 0.9155\n",
      "Epoch 172/250\n",
      " - 1s - loss: 0.1959 - acc: 0.9123\n",
      "Epoch 173/250\n",
      " - 1s - loss: 0.1886 - acc: 0.9184\n",
      "Epoch 174/250\n",
      " - 1s - loss: 0.1900 - acc: 0.9135\n",
      "Epoch 175/250\n",
      " - 1s - loss: 0.1961 - acc: 0.9091\n",
      "Epoch 176/250\n",
      " - 1s - loss: 0.1863 - acc: 0.9181\n",
      "Epoch 177/250\n",
      " - 1s - loss: 0.1856 - acc: 0.9169\n",
      "Epoch 178/250\n",
      " - 1s - loss: 0.1891 - acc: 0.9166\n",
      "Epoch 179/250\n",
      " - 1s - loss: 0.1884 - acc: 0.9174\n",
      "Epoch 180/250\n",
      " - 1s - loss: 0.1938 - acc: 0.9138\n",
      "Epoch 181/250\n",
      " - 1s - loss: 0.1888 - acc: 0.9137\n",
      "Epoch 182/250\n",
      " - 1s - loss: 0.1900 - acc: 0.9119\n",
      "Epoch 183/250\n",
      " - 1s - loss: 0.1844 - acc: 0.9190\n",
      "Epoch 184/250\n",
      " - 1s - loss: 0.1878 - acc: 0.9158\n",
      "Epoch 185/250\n",
      " - 1s - loss: 0.1867 - acc: 0.9166\n",
      "Epoch 186/250\n",
      " - 1s - loss: 0.1875 - acc: 0.9201\n",
      "Epoch 187/250\n",
      " - 1s - loss: 0.1874 - acc: 0.9161\n",
      "Epoch 188/250\n",
      " - 1s - loss: 0.1882 - acc: 0.9145\n",
      "Epoch 189/250\n",
      " - 1s - loss: 0.1841 - acc: 0.9190\n",
      "Epoch 190/250\n",
      " - 1s - loss: 0.1839 - acc: 0.9212\n",
      "Epoch 191/250\n",
      " - 1s - loss: 0.1834 - acc: 0.9213\n",
      "Epoch 192/250\n",
      " - 1s - loss: 0.1849 - acc: 0.9152\n",
      "Epoch 193/250\n",
      " - 1s - loss: 0.1813 - acc: 0.9190\n",
      "Epoch 194/250\n",
      " - 1s - loss: 0.1818 - acc: 0.9152\n",
      "Epoch 195/250\n",
      " - 1s - loss: 0.1813 - acc: 0.9192\n",
      "Epoch 196/250\n",
      " - 1s - loss: 0.1831 - acc: 0.9174\n",
      "Epoch 197/250\n",
      " - 1s - loss: 0.1823 - acc: 0.9192\n",
      "Epoch 198/250\n",
      " - 1s - loss: 0.1849 - acc: 0.9203\n",
      "Epoch 199/250\n",
      " - 1s - loss: 0.1790 - acc: 0.9216\n",
      "Epoch 200/250\n",
      " - 1s - loss: 0.1816 - acc: 0.9206\n",
      "Epoch 201/250\n",
      " - 1s - loss: 0.1813 - acc: 0.9212\n",
      "Epoch 202/250\n",
      " - 1s - loss: 0.1834 - acc: 0.9193\n",
      "Epoch 203/250\n",
      " - 1s - loss: 0.1852 - acc: 0.9184\n",
      "Epoch 204/250\n",
      " - 1s - loss: 0.1837 - acc: 0.9221\n",
      "Epoch 205/250\n",
      " - 1s - loss: 0.1833 - acc: 0.9178\n",
      "Epoch 206/250\n",
      " - 1s - loss: 0.1755 - acc: 0.9250\n",
      "Epoch 207/250\n",
      " - 1s - loss: 0.1787 - acc: 0.9222\n",
      "Epoch 208/250\n",
      " - 1s - loss: 0.1720 - acc: 0.9257\n",
      "Epoch 209/250\n",
      " - 1s - loss: 0.1867 - acc: 0.9117\n",
      "Epoch 210/250\n",
      " - 1s - loss: 0.1781 - acc: 0.9244\n",
      "Epoch 211/250\n",
      " - 1s - loss: 0.1758 - acc: 0.9216\n",
      "Epoch 212/250\n",
      " - 1s - loss: 0.1749 - acc: 0.9248\n",
      "Epoch 213/250\n",
      " - 1s - loss: 0.1764 - acc: 0.9227\n",
      "Epoch 214/250\n",
      " - 1s - loss: 0.1749 - acc: 0.9233\n",
      "Epoch 215/250\n",
      " - 1s - loss: 0.1723 - acc: 0.9233\n",
      "Epoch 216/250\n",
      " - 1s - loss: 0.1787 - acc: 0.9227\n",
      "Epoch 217/250\n",
      " - 1s - loss: 0.1790 - acc: 0.9193\n",
      "Epoch 218/250\n",
      " - 1s - loss: 0.1696 - acc: 0.9270\n",
      "Epoch 219/250\n",
      " - 1s - loss: 0.1718 - acc: 0.9262\n",
      "Epoch 220/250\n",
      " - 1s - loss: 0.1760 - acc: 0.9239\n",
      "Epoch 221/250\n",
      " - 1s - loss: 0.1778 - acc: 0.9212\n",
      "Epoch 222/250\n",
      " - 1s - loss: 0.1726 - acc: 0.9241\n",
      "Epoch 223/250\n",
      " - 1s - loss: 0.1719 - acc: 0.9233\n",
      "Epoch 224/250\n",
      " - 1s - loss: 0.1756 - acc: 0.9233\n",
      "Epoch 225/250\n",
      " - 1s - loss: 0.1678 - acc: 0.9286\n",
      "Epoch 226/250\n",
      " - 1s - loss: 0.1702 - acc: 0.9233\n",
      "Epoch 227/250\n",
      " - 1s - loss: 0.1718 - acc: 0.9238\n",
      "Epoch 228/250\n",
      " - 1s - loss: 0.1699 - acc: 0.9279\n",
      "Epoch 229/250\n",
      " - 1s - loss: 0.1762 - acc: 0.9206\n",
      "Epoch 230/250\n",
      " - 1s - loss: 0.1681 - acc: 0.9268\n",
      "Epoch 231/250\n",
      " - 1s - loss: 0.1658 - acc: 0.9277\n",
      "Epoch 232/250\n",
      " - 1s - loss: 0.1664 - acc: 0.9279\n",
      "Epoch 233/250\n",
      " - 1s - loss: 0.1658 - acc: 0.9271\n",
      "Epoch 234/250\n",
      " - 1s - loss: 0.1632 - acc: 0.9268\n",
      "Epoch 235/250\n",
      " - 1s - loss: 0.1708 - acc: 0.9288\n",
      "Epoch 236/250\n",
      " - 1s - loss: 0.1693 - acc: 0.9248\n",
      "Epoch 237/250\n",
      " - 1s - loss: 0.1630 - acc: 0.9297\n",
      "Epoch 238/250\n",
      " - 1s - loss: 0.1613 - acc: 0.9306\n",
      "Epoch 239/250\n",
      " - 1s - loss: 0.1658 - acc: 0.9288\n",
      "Epoch 240/250\n",
      " - 1s - loss: 0.1659 - acc: 0.9279\n",
      "Epoch 241/250\n",
      " - 1s - loss: 0.1639 - acc: 0.9285\n",
      "Epoch 242/250\n",
      " - 1s - loss: 0.1631 - acc: 0.9265\n",
      "Epoch 243/250\n",
      " - 1s - loss: 0.1658 - acc: 0.9271\n",
      "Epoch 244/250\n",
      " - 1s - loss: 0.1614 - acc: 0.9270\n",
      "Epoch 245/250\n",
      " - 1s - loss: 0.1636 - acc: 0.9279\n",
      "Epoch 246/250\n",
      " - 1s - loss: 0.1658 - acc: 0.9277\n",
      "Epoch 247/250\n",
      " - 1s - loss: 0.1609 - acc: 0.9285\n",
      "Epoch 248/250\n",
      " - 1s - loss: 0.1669 - acc: 0.9254\n",
      "Epoch 249/250\n",
      " - 1s - loss: 0.1607 - acc: 0.9312\n",
      "Epoch 250/250\n",
      " - 1s - loss: 0.1615 - acc: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a50188be0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    one_hot_y_train,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2647 - acc: 0.8838\n",
      "Normal Neural Network - Loss: 0.26471680331862746, Accuracy: 0.883806049823761\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, one_hot_y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3382 - acc: 0.8888\n",
      "Deep Neural Network - Loss: 0.3381931368953464, Accuracy: 0.8888380527496338\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, one_hot_y_test, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
